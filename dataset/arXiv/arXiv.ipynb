{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:           125G         12G         93G         17M         19G        111G\n",
      "Swap:            0B          0B          0B\n",
      "total 3.7G\n",
      "drwxrwxr-x 3 xiaowentao xiaowentao  227 11月 21 23:39 .\n",
      "drwxrwxr-x 4 xiaowentao xiaowentao  245 11月 22 00:41 ..\n",
      "-rw-rw-r-- 1 xiaowentao xiaowentao 692M 9月  22 23:57 arxiv-metadata-hash-abstracts-v0.2.0-2019-03-01.json\n",
      "-rw-rw-r-- 1 xiaowentao xiaowentao 2.7G 11月 15 00:54 arxiv-metadata-oai-snapshot.json\n",
      "-rw-rw-r-- 1 xiaowentao xiaowentao 185M 9月  22 23:46 authors-parsed-v0.2.0-2019-03-01.json\n",
      "-rw-rw-r-- 1 xiaowentao xiaowentao 126M 9月  22 23:46 internal-references-v0.2.0-2019-03-01.json\n",
      "drwxrwxr-x 2 xiaowentao xiaowentao    6 9月  22 23:53 .ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "!free -h \n",
    "!ls -alh decompressed\n",
    "\n",
    "# Source:\n",
    "# https://www.kaggle.com/Cornell-University/arxiv\n",
    "# http://arxiv.org/abs/1905.00075v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 67.24637126922607s.\n",
      "Metadata:\n",
      " {'id': '0704.0001', 'submitter': 'Pavel Nadolsky', 'authors': \"C. Bal\\\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\", 'title': 'Calculation of prompt diphoton production cross sections at Tevatron and\\n  LHC energies', 'comments': '37 pages, 15 figures; published version', 'journal-ref': 'Phys.Rev.D76:013009,2007', 'doi': '10.1103/PhysRevD.76.013009', 'report-no': 'ANL-HEP-PR-07-12', 'categories': 'hep-ph', 'license': None, 'abstract': '  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n', 'versions': [{'version': 'v1', 'created': 'Mon, 2 Apr 2007 19:18:42 GMT'}, {'version': 'v2', 'created': 'Tue, 24 Jul 2007 20:10:27 GMT'}], 'update_date': '2008-11-26', 'authors_parsed': [['Balázs', 'C.', ''], ['Berger', 'E. L.', ''], ['Nadolsky', 'P. M.', ''], ['Yuan', 'C. -P.', '']]}\n",
      "\n",
      "{'id': '0704.0002', 'submitter': 'Louis Theran', 'authors': 'Ileana Streinu and Louis Theran', 'title': 'Sparsity-certifying Graph Decompositions', 'comments': 'To appear in Graphs and Combinatorics', 'journal-ref': None, 'doi': None, 'report-no': None, 'categories': 'math.CO cs.CG', 'license': 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/', 'abstract': '  We describe a new algorithm, the $(k,\\\\ell)$-pebble game with colors, and use\\nit obtain a characterization of the family of $(k,\\\\ell)$-sparse graphs and\\nalgorithmic solutions to a family of problems concerning tree decompositions of\\ngraphs. Special instances of sparse graphs appear in rigidity theory and have\\nreceived increased attention in recent years. In particular, our colored\\npebbles generalize and strengthen the previous results of Lee and Streinu and\\ngive a new proof of the Tutte-Nash-Williams characterization of arboricity. We\\nalso present a new decomposition that certifies sparsity based on the\\n$(k,\\\\ell)$-pebble game with colors. Our work also exposes connections between\\npebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\\nWestermann and Hendrickson.\\n', 'versions': [{'version': 'v1', 'created': 'Sat, 31 Mar 2007 02:26:18 GMT'}, {'version': 'v2', 'created': 'Sat, 13 Dec 2008 17:26:00 GMT'}], 'update_date': '2008-12-13', 'authors_parsed': [['Streinu', 'Ileana', ''], ['Theran', 'Louis', '']]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from itertools import chain\n",
    "import random\n",
    "import socket\n",
    "import socks\n",
    "import numpy as np\n",
    "import os\n",
    "from queue import Queue\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2'\n",
    "# Force use CPU\n",
    "# https://github.com/tensorflow/tensorflow/issues/31135\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "# Set CPU as available physical device\n",
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# print(f'physical_devices: {physical_devices}')\n",
    "# tf.config.set_visible_devices(physical_devices[0:2], 'GPU')\n",
    "import tensorflow_hub as hub\n",
    "socks.set_default_proxy(socks.SOCKS5, \"127.0.0.1\", 1080)\n",
    "socket.socket = socks.socksocket\n",
    "\n",
    "# params\n",
    "verbose = True\n",
    "min_edge = 20\n",
    "max_edge = 400\n",
    "min_graph = 500\n",
    "\n",
    "metadata = []\n",
    "st = time()\n",
    "with open(list(Path('decompressed').glob('arxiv-metadata-oai*'))[0], 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        metadata.append(json.loads(line))\n",
    "    metadata_id_dict = {v['id']: i for i, v in enumerate(metadata)}\n",
    "    if verbose:\n",
    "        print(f'Done with {time() - st}s.')\n",
    "        print('Metadata:\\n', '\\n\\n'.join(map(lambda x: str(x), metadata[:1])))\n",
    "        print(metadata[metadata_id_dict[citation['1307.7980'][2]]])\n",
    "\n",
    "citation = []\n",
    "st = time()\n",
    "with open(list(Path('decompressed').glob('internal-references*'))[0], 'r') as f:\n",
    "    citation = json.loads(f.readlines()[0])\n",
    "    if verbose:\n",
    "        print(f'Done with {time() - st}s\\n',\n",
    "              'Citation:\\n', citation['1307.7980'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: 1793457, citation: 1354753\n",
      "category_stat (len=149): {'gr-qc': 22341, 'q-bio.PE': 1490, 'q-bio.BM': 444, 'q-bio.MN': 475, 'q-bio.QM': 494, 'q-bio.SC': 122, 'q-bio.NC': 983, 'q-bio.GN': 284, 'q-bio.CB': 141, 'q-bio.TO': 146, 'q-bio.OT': 104, 'hep-ph': 68452, 'physics.soc-ph': 1583, 'physics.ins-det': 2211, 'physics.atom-ph': 4372, 'physics.class-ph': 1229, 'physics.chem-ph': 1672, 'physics.geo-ph': 527, 'physics.hist-ph': 358, 'physics.optics': 6227, 'physics.flu-dyn': 4727, 'physics.ed-ph': 618, 'physics.ao-ph': 520, 'physics.plasm-ph': 3384, 'physics.gen-ph': 3596, 'physics.atm-clus': 299, 'physics.acc-ph': 1551, 'physics.data-an': 630, 'physics.comp-ph': 963, 'physics.med-ph': 460, 'physics.pop-ph': 177, 'physics.bio-ph': 548, 'physics.space-ph': 295, 'math.GT': 5844, 'math.HO': 809, 'math.SP': 1173, 'math.DG': 10972, 'math.CV': 4107, 'math.CO': 16819, 'math.OA': 2620, 'math.AG': 13844, 'math.RA': 4045, 'math.GR': 5177, 'math.PR': 15722, 'math.GM': 1303, 'math.OC': 7492, 'math.NT': 13218, 'math.AP': 18602, 'math.RT': 4749, 'math.CA': 6434, 'math.MG': 1791, 'math.AT': 2774, 'math.QA': 2455, 'math.NA': 8594, 'math.LO': 4102, 'math.CT': 936, 'math.FA': 7788, 'math.DS': 8167, 'math.GN': 1158, 'math.KT': 543, 'math.SG': 1217, 'math.AC': 2969, 'astro-ph': 84430, 'cond-mat.str-el': 18467, 'cond-mat.stat-mech': 15397, 'cond-mat.other': 3370, 'cond-mat.mes-hall': 22041, 'cond-mat.soft': 8285, 'cond-mat.mtrl-sci': 15538, 'cond-mat.dis-nn': 3370, 'cond-mat.supr-con': 10694, 'cond-mat': 9074, 'cond-mat.quant-gas': 4250, 'cs.SE': 1717, 'cs.CR': 2972, 'cs.LG': 2302, 'cs.DS': 4384, 'cs.RO': 1892, 'cs.CC': 1373, 'cs.CL': 4517, 'cs.DM': 1011, 'cs.NI': 3929, 'cs.AI': 3041, 'cs.CE': 342, 'cs.DC': 2556, 'cs.LO': 3146, 'cs.PL': 1322, 'cs.DB': 1399, 'cs.SC': 359, 'cs.CG': 1280, 'cs.GL': 26, 'cs.NA': 282, 'cs.NE': 798, 'cs.GR': 368, 'cs.IR': 846, 'cs.MM': 308, 'cs.DL': 257, 'cs.GT': 1739, 'cs.MS': 172, 'cs.AR': 302, 'cs.OH': 434, 'cs.CV': 13230, 'cs.PF': 218, 'cs.SD': 245, 'cs.MA': 214, 'cs.CY': 640, 'q-fin.GN': 199, 'cs.HC': 576, 'cs.OS': 115, 'astro-ph.CO': 16935, 'quant-ph': 44667, 'hep-th': 49552, 'stat.ME': 4784, 'astro-ph.EP': 7695, 'astro-ph.HE': 13780, 'astro-ph.SR': 19506, 'hep-ex': 14718, 'stat.CO': 985, 'nlin.CD': 2875, 'astro-ph.GA': 16325, 'nucl-th': 16120, 'q-fin.PR': 295, 'nucl-ex': 5984, 'hep-lat': 9007, 'astro-ph.IM': 4234, 'q-fin.TR': 189, 'cs.FL': 806, 'stat.AP': 2435, 'q-fin.PM': 165, 'nlin.PS': 1427, 'nlin.SI': 1933, 'stat.OT': 155, 'q-fin.RM': 218, 'nlin.AO': 510, 'stat.ML': 1511, 'q-fin.ST': 296, 'cs.SY': 2184, 'cs.SI': 800, 'q-fin.CP': 197, 'cs.ET': 293, 'q-fin.MF': 307, 'nlin.CG': 156, 'q-fin.EC': 126, 'physics.app-ph': 362, 'eess.SP': 996, 'econ.EM': 147, 'eess.IV': 129, 'eess.AS': 16, 'econ.TH': 48}(65 keys with values >= 2000)\n",
      "\n",
      "category_stat_coarse (len=19): {'gr-qc': 22341, 'q-bio': 4683, 'hep-ph': 68452, 'physics': 36309, 'math': 175424, 'astro-ph': 162905, 'cond-mat': 110486, 'cs': 62395, 'q-fin': 1992, 'quant-ph': 44667, 'hep-th': 49552, 'stat': 9870, 'hep-ex': 14718, 'nlin': 6901, 'nucl-th': 16120, 'nucl-ex': 5984, 'hep-lat': 9007, 'eess': 1141, 'econ': 195}\n",
      "category_stat of subclasses of \"cs\" with more than 2000 papers:\n",
      "[('cs.CR', 2972), ('cs.LG', 2302), ('cs.DS', 4384), ('cs.CL', 4517), ('cs.NI', 3929), ('cs.AI', 3041), ('cs.DC', 2556), ('cs.LO', 3146), ('cs.CV', 13230), ('cs.SY', 2184)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'metadata: {len(metadata)}, citation: {len(citation)}')\n",
    "category_stat = {}\n",
    "category_stat_coarse = {}\n",
    "for p in citation:\n",
    "    if p in metadata_id_dict:\n",
    "        c = metadata[metadata_id_dict[p]]['categories']\n",
    "        if ' ' not in c:\n",
    "            # if single category\n",
    "            if c not in category_stat:\n",
    "                category_stat[c] = 1\n",
    "            else:\n",
    "                category_stat[c] += 1\n",
    "            c = c.split('.')[0]\n",
    "            if c not in category_stat_coarse:\n",
    "                category_stat_coarse[c] = 1\n",
    "            else:\n",
    "                category_stat_coarse[c] += 1\n",
    "if verbose:\n",
    "    print(f'category_stat (len={len(category_stat)}): {category_stat}' +\n",
    "          f'({len(list(filter(lambda x: x[1] >= 2000, category_stat.items())))}' +\n",
    "          f' keys with values >= 2000)\\n\\ncategory_stat_coarse (len=' +\n",
    "          f'{len(category_stat_coarse)}): {category_stat_coarse}')\n",
    "\n",
    "category_target_stat = list(filter(lambda x: x[0].startswith(\"cs.\") and x[1] >= 2000,\n",
    "                                   category_stat.items()))\n",
    "category_target = set(map(lambda x: x[0], category_target_stat))\n",
    "print('category_stat of subclasses of \"cs\" with more than 2000 papers:\\n' +\n",
    "      f'{category_target_stat}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "cnt: 4.00w/135w, with 0.0s/10000\n",
      "cnt: 8.00w/135w, with 0.0s/10000\n",
      "cnt: 12.00w/135w, with 0.0s/10000\n",
      "cnt: 16.00w/135w, with 0.1s/10000\n",
      "cnt: 20.00w/135w, with 0.4s/10000\n",
      "cnt: 24.00w/135w, with 0.8s/10000\n",
      "cnt: 28.00w/135w, with 1.0s/10000\n",
      "cnt: 32.00w/135w, with 1.5s/10000\n",
      "cnt: 36.00w/135w, with 1.6s/10000\n",
      "cnt: 40.00w/135w, with 1.6s/10000\n",
      "cnt: 44.00w/135w, with 1.6s/10000\n",
      "cnt: 48.00w/135w, with 1.7s/10000\n",
      "cnt: 52.00w/135w, with 1.7s/10000\n",
      "cnt: 56.00w/135w, with 1.7s/10000\n",
      "cnt: 60.00w/135w, with 1.8s/10000\n",
      "cnt: 64.00w/135w, with 1.7s/10000\n",
      "cnt: 68.00w/135w, with 1.7s/10000\n",
      "cnt: 72.00w/135w, with 1.6s/10000\n",
      "debug: cnt_fail = 6369, cnt_empty_ref = 529\n",
      "#graph = 12982\n",
      "\n",
      "dataset: {'cs.DC': 244, 'cs.AI': 553, 'cs.LG': 885, 'cs.CR': 273, 'cs.CL': 2318, 'cs.CV': 7435, 'cs.DS': 621, 'cs.NI': 283, 'cs.SY': 166, 'cs.LO': 204}\n",
      "\n",
      "{'cs.DC': {'nodes': 2202.905737704918, 'uni_nodes': 455.3524590163934, 'edge': 384.5163934426229}, 'cs.AI': {'nodes': 2280.4068716094034, 'uni_nodes': 420.9186256781193, 'edge': 397.61844484629296}, 'cs.LG': {'nodes': 2103.74802259887, 'uni_nodes': 324.84293785310734, 'edge': 398.08474576271186}, 'cs.CR': {'nodes': 1836.923076923077, 'uni_nodes': 309.1172161172161, 'edge': 387.61538461538464}, 'cs.CL': {'nodes': 2319.0470232959447, 'uni_nodes': 381.93270060396895, 'edge': 396.69801553062985}, 'cs.CV': {'nodes': 2487.365971755212, 'uni_nodes': 342.1332885003362, 'edge': 399.8855413584398}, 'cs.DS': {'nodes': 1433.0096618357488, 'uni_nodes': 179.81159420289856, 'edge': 384.6280193236715}, 'cs.NI': {'nodes': 1626.4805653710248, 'uni_nodes': 192.30388692579504, 'edge': 390.47703180212017}, 'cs.SY': {'nodes': 1591.289156626506, 'uni_nodes': 215.98192771084337, 'edge': 398.7048192771084}, 'cs.LO': {'nodes': 2393.5343137254904, 'uni_nodes': 556.8823529411765, 'edge': 393.2450980392157}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_valid_id = lambda pid: pid in metadata_id_dict and pid in citation\n",
    "dbg = {c: {'nodes': [], 'uni_nodes': [], 'edge': []} for c in category_target}\n",
    "graphs = []\n",
    "dataset = {c: [] for c in category_target}\n",
    "cnt = 0\n",
    "cnt_empty_ref = 0\n",
    "cnt_fail = 0\n",
    "st = time()\n",
    "print('start construct graphs.')\n",
    "\n",
    "for pid, refs in filter(lambda x: len(x[1]) >= min_width, citation.items()):\n",
    "    cnt += 1\n",
    "    if cnt % 40000 == 0:\n",
    "        print(f'cnt: {cnt / 10000:.2f}w/135w, with {(time() - st) / cnt * 10000:.1f}s/10000')\n",
    "    category = metadata[metadata_id_dict[pid]]['categories']\n",
    "    if category not in category_target:\n",
    "        continue\n",
    "    refs = list(filter(check_valid_id, refs))\n",
    "    if len(refs) == 0:\n",
    "        cnt_empty_ref += 1\n",
    "        continue\n",
    "    q = Queue()\n",
    "    for r in refs:\n",
    "        q.put(r)\n",
    "    # one paper with its ciatations construct one edge\n",
    "    edges = [[pid, ] + refs, ]\n",
    "    while q.qsize() > 0 and len(edges) <= max_edge:\n",
    "        curr = q.get()\n",
    "        refs = list(filter(check_valid_id, citation[curr]))\n",
    "        edges.append([curr, ] + refs)\n",
    "        for r in refs:\n",
    "            q.put(r)\n",
    "    if len(edges) >= min_edge:\n",
    "        graphs.append([pid, edges])\n",
    "        dataset[category].append(len(graphs) - 1)\n",
    "        nodes = list(chain.from_iterable(edges))\n",
    "        dbg[category]['nodes'].append(len(nodes))\n",
    "        dbg[category]['uni_nodes'].append(len(set(nodes)))\n",
    "        dbg[category]['edge'].append(len(edges))\n",
    "    else:\n",
    "        cnt_fail += 1\n",
    "\n",
    "dataset_stat = {k: len(v) for k, v in dataset.items()}\n",
    "dbg = {c: dict(map(lambda x: [x[0], round(sum(x[1]) / len(x[1]), 2)], dbg[c].items())) for c in dbg}\n",
    "if verbose:\n",
    "    print(f'cnt_fail = {cnt_fail}, cnt_empty_ref = {cnt_empty_ref}')\n",
    "print(f'#graph = {len(graphs)}\\n\\ndataset: {dataset_stat}\\n\\n' +\n",
    "      f'{dbg}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "dataset_target_final: {'cs.AI', 'cs.LG', 'cs.CL', 'cs.CV', 'cs.DS'}\n",
      "#corpus=67809\n",
      "Embedding 67809 paper corpus with 46.120678186416626s.\n"
     ]
    }
   ],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "\n",
    "def get_paper_text(pid):\n",
    "    meta = metadata[metadata_id_dict[pid]]\n",
    "    return str(meta['title'].replace('\\n', ' ') + '. ' + meta['abstract'].replace('\\n', ' '))\n",
    "\n",
    "\n",
    "dataset_target_final = set([k for k, v in dataset_stat.items() if v >= min_graph])\n",
    "print(f'dataset_target_final: {dataset_target_final}')\n",
    "# if #samples >= 1000, then subsampling to 700\n",
    "dataset_downsample = {c: (random.sample(d, len(d)) if dataset_stat[c] <= 1000 else \\\n",
    "           random.sample(d, 700)) for c, d in dataset.items() if c in dataset_target_final}\n",
    "print(f'dataset: {[[c, len(v)] for c, v in dataset_downsample.items()]}')\n",
    "\n",
    "st = time()\n",
    "dataset_pids = set([graphs[i][0] for i in list(chain.from_iterable(\n",
    "    dataset_downsample.values()))])\n",
    "# Get node features\n",
    "pids = list(set(chain.from_iterable([set(chain.from_iterable(x[1])) for x in graphs if x[0] in dataset_pids])))\n",
    "# decrease memory usage\n",
    "graphs = [g if g[0] in dataset_pids else [g[0], None] for g in graphs]\n",
    "corpus = {p: get_paper_text(p) for p in pids}\n",
    "print(f'#corpus={len(corpus)}')\n",
    "batch_size = 2048\n",
    "for idx in range(int(np.ceil(len(corpus) / batch_size))):\n",
    "    curr_range = pids[idx * batch_size: (idx + 1) * batch_size]\n",
    "    # => 512-d feature vector\n",
    "    emb = embed([corpus[i] for i in curr_range]).numpy()\n",
    "    for i, pid in enumerate(curr_range):\n",
    "        corpus[pid] = emb[i]\n",
    "print(f'Embedding {len(corpus)} paper corpus with {time() - st}s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导出文件：graphs: [..., [pid_i, edges_i], ...], 其中 pid_i 为第 i 个 graph 构造的时候的起始论文的 ArXiv ID，\n",
    "# edges_i 为  [..., [pid_j0, ..., pid_jn], ...] 为第 i 个 graph 的超边集，每一条边长度不一样，例如第 j 条超边\n",
    "# 长度为 jn，pid_j0 表示论文的 ArXiv ID。\n",
    "# dataset: {class: [gid_0, ...], ...}，共有五个类：{'cs.AI', 'cs.LG', 'cs.CL', 'cs.CV', 'cs.DS'},\n",
    "# 每个类对应一个数组，数组里面就是相应的 graph 的索引。\n",
    "# corpus: {pid: paper_embd, ...}, 为 ArXiv ID 对应 paper 的标题和摘要的 embedding（512-D vector）。\n",
    "st = time()\n",
    "np.savez_compressed('arxiv_hypergraph_preprocessed.npz',\n",
    "                    graphs=graphs,\n",
    "                    dataset=dataset_downsample,\n",
    "                    corpus=corpus)\n",
    "print(f'File written into {os.path.abspath(\"arxiv_hypergraph_unsplited.npz\")}' +\n",
    "      f'\\n(size={os.path.getsize(\"arxiv_hypergraph_unsplited.npz\")})' +\n",
    "      f' with {time() - st}s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construct hypergraph done with 23.48652410507202s.\n"
     ]
    }
   ],
   "source": [
    "def construct_hypergraph(edges, test_pid, test=False):\n",
    "    # construct hypergraph H with shape (N, E)\n",
    "    pid2nid = {pid: i for i, pid in enumerate(chain.from_iterable(edges))}\n",
    "    coo_matrix_H = list(chain.from_iterable([\n",
    "        [[pid2nid[p], e_id] for p in edge if (test or (p not in test_pid))] for e_id, edge in enumerate(edges)]))\n",
    "    coo_matrix_H = sorted(coo_matrix_H, key=lambda x: x[0])\n",
    "    row = [i[0] for i in coo_matrix_H]\n",
    "    col = [i[1] for i in coo_matrix_H]\n",
    "    # currently all elements in H are 1\n",
    "    data = [1.] * len(row)\n",
    "    node_features = np.stack([corpus[i[0]] for i in sorted(\n",
    "        [[k, v] for k, v in pid2nid.items()], key=lambda x: x[1])])\n",
    "    return {'H': [data, (row, col)], 'X': node_features}\n",
    "\n",
    "st = time()\n",
    "# split: 70% training, 30% testing (10% validation, 20% testing)\n",
    "ratio = .7\n",
    "dataset_train = {c: d[:int(ratio * len(d))] for c, d in dataset_downsample.items()}\n",
    "dataset_test = {c: d[int(ratio * len(d)):] for c, d in dataset_downsample.items()}\n",
    "# In order to prevent a leaking of the test set into the trainingset,\n",
    "# using the train/test partition that we omitted citations from articles\n",
    "# in the training set which connect to the test set, but retained citations\n",
    "# in the test set which connect to the training set.\n",
    "test_pid_by_class = {c: set([graphs[i][0] for i in d]) for c, d in dataset_test.items()}\n",
    "dataset_train = {c: {graphs[i][0]: construct_hypergraph(\n",
    "    graphs[i][1], test_pid_by_class[c]) for i in d} for c, d in dataset_train.items()}\n",
    "dataset_test = {c: {graphs[i][0]: construct_hypergraph(\n",
    "    graphs[i][1], test_pid_by_class[c], test=True) for i in d} for c, d in dataset_test.items()}\n",
    "print(f'Construct hypergraph done with {time() - st}s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21:51:04 up 11 days,  4:22, 21 users,  load average: 47.64, 46.37, 46.11\n",
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:           125G         34G         56G         83M         34G         90G\n",
      "Swap:            0B          0B          0B\n",
      "Tue Nov 24 21:51:04 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:18:00.0 Off |                  N/A |\n",
      "| 22%   34C    P2    62W / 250W |   5508MiB / 11019MiB |     13%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 22%   36C    P2    60W / 250W |   5534MiB / 11019MiB |     11%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:86:00.0 Off |                  N/A |\n",
      "| 22%   36C    P2    59W / 250W |   1376MiB / 11019MiB |     20%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:AF:00.0 Off |                  N/A |\n",
      "| 33%   58C    P2   219W / 250W |   5646MiB / 11019MiB |     47%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    177951      C   python                           5505MiB |\n",
      "|    1   N/A  N/A    177036      C   python                           5531MiB |\n",
      "|    2   N/A  N/A    941860      C   python                           1373MiB |\n",
      "|    3   N/A  N/A    315168      C   python                           5643MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!uptime && free -h && nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
